#!/usr/bin/env python3
"""
æµ‹è¯•æ—¶é—´å€’åºæ’åˆ—åŠŸèƒ½

éªŒè¯READMEæ›´æ–°é€»è¾‘æ˜¯å¦æ­£ç¡®åœ°å°†æœ€æ–°è®ºæ–‡æ”¾åœ¨æœ€å‰é¢ï¼Œ
ç¡®ä¿è®ºæ–‡å§‹ç»ˆæŒ‰æ—¶é—´å€’åºæ’åˆ—ã€‚
"""

import os
import sys
import tempfile
from datetime import datetime, timezone

# Add the parent directory to the path so we can import the main module
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.fetch_papers import GitHubUpdater


def test_reverse_chronological_order():
    """æµ‹è¯•æ—¶é—´å€’åºæ’å…¥é€»è¾‘"""
    
    print("ğŸ” æµ‹è¯•READMEæ—¶é—´å€’åºæ’åˆ—åŠŸèƒ½")
    print("=" * 60)
    
    # Create a mock README content
    mock_readme_content = """# ArXiv Social Good AI Paper Fetcher

An automated system for discovering and cataloging research papers related to AI bias, fairness, and social good from arXiv.org.

## ğŸ¯ Features

- **Intelligent Paper Detection**: Uses GPT-4o to analyze papers
- **Automated Daily Updates**: Runs daily via GitHub Actions

## ğŸ”§ Setup & Configuration

Setup instructions here...

## ğŸš€ Usage

Usage instructions here...

**Note**: This tool is designed for academic research purposes. Please respect arXiv's usage policies.

## Papers Updated on 2024-01-15 08:00 UTC

### Old Paper 1

**Authors:** Author A, Author B

**Categories:** cs.AI, cs.LG

**Published:** 2024-01-14T10:00:00Z

**Abstract:** This is an old paper abstract...

**Link:** [arXiv:2401.12345](https://arxiv.org/abs/2401.12345)

---

### Old Paper 2

**Authors:** Author C, Author D

**Categories:** cs.CL

**Published:** 2024-01-13T15:30:00Z

**Abstract:** This is another old paper abstract...

**Link:** [arXiv:2401.12346](https://arxiv.org/abs/2401.12346)

---
"""
    
    print("ğŸ“„ æ¨¡æ‹Ÿçš„ç°æœ‰READMEå†…å®¹:")
    print("   - åŒ…å«é¡¹ç›®æè¿°å’Œè®¾ç½®è¯´æ˜")
    print("   - å·²æœ‰2ç¯‡æ—§è®ºæ–‡ (2024-01-15 å’Œ 2024-01-13)")
    print("   - æµ‹è¯•æ–°è®ºæ–‡æ˜¯å¦ä¼šæ’å…¥åˆ°æ­£ç¡®ä½ç½®")
    
    # Create mock new papers (should be inserted at the top)
    new_papers = [
        {
            'title': 'Brand New Paper on AI Fairness',
            'authors': ['New Author A', 'New Author B', 'New Author C', 'New Author D'],
            'categories': ['cs.AI', 'cs.LG', 'cs.CL'],
            'published': '2024-01-16T12:00:00Z',
            'abstract': 'This is a brand new paper about AI fairness that should appear at the top of the README.',
            'link': 'https://arxiv.org/abs/2401.99999',
            'arxiv_id': '2401.99999'
        },
        {
            'title': 'Another New Paper on Social Good AI',
            'authors': ['New Author E', 'New Author F'],
            'categories': ['cs.AI', 'cs.HC'],
            'published': '2024-01-16T09:30:00Z',
            'abstract': 'This is another new paper about social good AI applications.',
            'link': 'https://arxiv.org/abs/2401.99998',
            'arxiv_id': '2401.99998'
        }
    ]
    
    print(f"\nğŸ“ æ¨¡æ‹Ÿæ·»åŠ  {len(new_papers)} ç¯‡æ–°è®ºæ–‡:")
    for i, paper in enumerate(new_papers, 1):
        print(f"   {i}. {paper['title'][:50]}... ({paper['published'][:10]})")
    
    # Test the insertion logic
    print(f"\nğŸ§ª æµ‹è¯•æ’å…¥ä½ç½®æŸ¥æ‰¾é€»è¾‘...")
    
    class MockGitHubUpdater(GitHubUpdater):
        def __init__(self):
            # Skip the parent __init__ to avoid GitHub API calls
            pass
        
        def test_insert_position(self, content):
            return self._find_papers_insert_position(content)
        
        def test_format_new_section(self, papers, section_title):
            new_section = f"\n\n## {section_title}\n\n"
            
            for paper in papers:
                # Format paper entry
                authors_str = ", ".join(paper['authors'][:3])  # First 3 authors
                if len(paper['authors']) > 3:
                    authors_str += " et al."
                
                categories_str = ", ".join(paper['categories'])
                
                new_section += f"### {paper['title']}\n\n"
                new_section += f"**Authors:** {authors_str}\n\n"
                new_section += f"**Categories:** {categories_str}\n\n"
                new_section += f"**Published:** {paper['published']}\n\n"
                new_section += f"**Abstract:** {paper['abstract']}\n\n"
                new_section += f"**Link:** [arXiv:{paper['arxiv_id']}]({paper['link']})\n\n"
                new_section += "---\n\n"
            
            return new_section
    
    # Test insertion position finding
    updater = MockGitHubUpdater()
    insert_pos = updater.test_insert_position(mock_readme_content)
    
    if insert_pos > 0:
        lines_before = mock_readme_content[:insert_pos].count('\n')
        print(f"   âœ… æ‰¾åˆ°æ’å…¥ä½ç½®: ç¬¬ {lines_before} è¡Œä¹‹å")
        
        # Show the context around insertion point
        lines = mock_readme_content.split('\n')
        context_start = max(0, lines_before - 2)
        context_end = min(len(lines), lines_before + 3)
        
        print(f"   ğŸ“ æ’å…¥ä½ç½®ä¸Šä¸‹æ–‡:")
        for i in range(context_start, context_end):
            if i < len(lines):
                marker = " >>> æ’å…¥ç‚¹ <<<" if i == lines_before else ""
                print(f"     {i+1:2d}: {lines[i][:50]}{marker}")
    else:
        print(f"   âš ï¸ æœªæ‰¾åˆ°åˆé€‚æ’å…¥ä½ç½®ï¼Œå°†ä½¿ç”¨æœ«å°¾è¿½åŠ ")
    
    # Test the complete update logic
    print(f"\nğŸ”„ æµ‹è¯•å®Œæ•´çš„æ›´æ–°é€»è¾‘...")
    
    section_title = f"Papers Updated on {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M UTC')}"
    new_section = updater.test_format_new_section(new_papers, section_title)
    
    if insert_pos > 0:
        updated_content = (mock_readme_content[:insert_pos] + 
                         new_section + 
                         mock_readme_content[insert_pos:])
        print(f"   âœ… æ–°å†…å®¹æ’å…¥åˆ°æ­£ç¡®ä½ç½®")
    else:
        updated_content = mock_readme_content + new_section
        print(f"   âš ï¸ æ–°å†…å®¹è¿½åŠ åˆ°æœ«å°¾")
    
    # Analyze the result
    print(f"\nğŸ“Š ç»“æœåˆ†æ:")
    
    # Find all paper sections in the updated content
    lines = updated_content.split('\n')
    paper_sections = []
    
    for i, line in enumerate(lines):
        if line.startswith('## Papers Updated on') or line.startswith('## Historical'):
            # Found a paper section header
            section_info = {
                'line': i + 1,
                'title': line,
                'date_str': None
            }
            
            # Extract date from title
            if 'Updated on' in line:
                try:
                    date_part = line.split('Updated on ')[1].split(' UTC')[0]
                    section_info['date_str'] = date_part
                except:
                    pass
            
            paper_sections.append(section_info)
    
    print(f"   - æ‰¾åˆ° {len(paper_sections)} ä¸ªè®ºæ–‡æ®µè½:")
    for i, section in enumerate(paper_sections, 1):
        print(f"     {i}. {section['title'][:60]}... (ç¬¬{section['line']}è¡Œ)")
    
    # Check if chronological order is correct
    if len(paper_sections) >= 2:
        first_section = paper_sections[0]
        second_section = paper_sections[1]
        
        print(f"\nğŸ¯ æ—¶é—´å€’åºéªŒè¯:")
        print(f"   - ç¬¬ä¸€ä¸ªæ®µè½: {first_section['title'][:40]}...")
        print(f"   - ç¬¬äºŒä¸ªæ®µè½: {second_section['title'][:40]}...")
        
        if first_section['date_str'] and second_section['date_str']:
            first_is_newer = first_section['date_str'] > second_section['date_str']
            if first_is_newer:
                print(f"   âœ… æ—¶é—´å€’åºæ­£ç¡®ï¼æœ€æ–°è®ºæ–‡åœ¨æœ€ä¸Šé¢")
            else:
                print(f"   âŒ æ—¶é—´å€’åºé”™è¯¯ï¼éœ€è¦è°ƒæ•´æ’å…¥é€»è¾‘")
        else:
            print(f"   â„¹ï¸ æ— æ³•æ¯”è¾ƒæ—¥æœŸï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
    
    # Save result to temporary file for inspection
    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
        f.write(updated_content)
        temp_file = f.name
    
    print(f"\nğŸ“„ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_file}")
    print(f"   å¯ä»¥æ‰‹åŠ¨æ£€æŸ¥READMEæ›´æ–°ç»“æœ")
    
    print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
    print(f"   å…³é”®æ”¹è¿›:")
    print(f"   - âœ… æ–°è®ºæ–‡ä¼šæ’å…¥åˆ°READMEå¼€å¤´éƒ¨åˆ†")
    print(f"   - âœ… ä¿æŒæ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°åœ¨ä¸Šï¼‰")
    print(f"   - âœ… é¿å…åœ¨æ–‡æ¡£æœ«å°¾è¿½åŠ ")
    print(f"   - âœ… æ™ºèƒ½è¯†åˆ«æ’å…¥ä½ç½®")


if __name__ == "__main__":
    test_reverse_chronological_order() 