#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ - è¯¦ç»†æ˜¾ç¤ºè®ºæ–‡æŠ“å–è¿‡ç¨‹

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºè°ƒè¯•å’Œè¯Šæ–­è®ºæ–‡æŠ“å–ç³»ç»Ÿï¼Œä¼šæ˜¾ç¤ºæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯ï¼Œ
å¸®åŠ©ç”¨æˆ·äº†è§£ç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œï¼Œä»¥åŠåœ¨å“ªä¸ªç¯èŠ‚å¯èƒ½å‡ºç°é—®é¢˜ã€‚
"""

import os
import sys
import logging
from datetime import datetime, timezone, timedelta

# è®¾ç½®è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
    ]
)

# Add the parent directory to the path so we can import the main module
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scripts.fetch_papers import ArxivPaperFetcher


def debug_arxiv_connection():
    """è°ƒè¯•arXivè¿æ¥"""
    print("ğŸ” æµ‹è¯•arXiv APIè¿æ¥...")
    
    import requests
    import feedparser
    
    try:
        # æµ‹è¯•æœ€åŸºæœ¬çš„arXivæŸ¥è¯¢
        url = "http://export.arxiv.org/api/query"
        params = {
            "search_query": "cat:cs.AI",
            "sortBy": "submittedDate", 
            "sortOrder": "descending",
            "max_results": 5
        }
        
        print(f"ğŸ“¡ å‘é€è¯·æ±‚åˆ°: {url}")
        print(f"ğŸ“‹ æŸ¥è¯¢å‚æ•°: {params}")
        
        response = requests.get(url, params=params, timeout=10)
        print(f"âœ… HTTPçŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            feed = feedparser.parse(response.content)
            entries = feed.entries
            print(f"ğŸ“„ è·å–åˆ° {len(entries)} ç¯‡è®ºæ–‡")
            
            if entries:
                print(f"ğŸ“ ç¬¬ä¸€ç¯‡è®ºæ–‡ç¤ºä¾‹:")
                entry = entries[0]
                print(f"   - æ ‡é¢˜: {entry.title}")
                print(f"   - å‘å¸ƒæ—¶é—´: {entry.published}")
                print(f"   - æ›´æ–°æ—¶é—´: {entry.updated}")
                print(f"   - ç±»åˆ«: {[tag.term for tag in entry.tags] if hasattr(entry, 'tags') else 'æ— '}")
                print(f"   - æ‘˜è¦é•¿åº¦: {len(entry.summary)} å­—ç¬¦")
                return True
        else:
            print(f"âŒ HTTPè¯·æ±‚å¤±è´¥: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ arXivè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def debug_openai_connection(api_key):
    """è°ƒè¯•OpenAIè¿æ¥"""
    print("\nğŸ¤– æµ‹è¯•OpenAI APIè¿æ¥...")
    
    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        # æµ‹è¯•ä¸€ä¸ªç®€å•çš„è¯·æ±‚
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are a helpful assistant. Respond with just the number 1."},
                {"role": "user", "content": "Test"}
            ],
            temperature=0,
            max_tokens=1
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ… OpenAI APIè¿æ¥æˆåŠŸ")
        print(f"ğŸ“¤ å‘é€æ¨¡å‹: gpt-4o")
        print(f"ğŸ“¨ APIå“åº”: '{result}'")
        return True
        
    except Exception as e:
        print(f"âŒ OpenAIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False


def debug_paper_fetch():
    """è°ƒè¯•è®ºæ–‡æŠ“å–è¿‡ç¨‹"""
    print("\n" + "="*60)
    print("ğŸ” ArXivè®ºæ–‡æŠ“å–ç³»ç»Ÿè°ƒè¯•")
    print("="*60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    openai_api_key = os.getenv("OPENAI_API_KEY")
    print(f"ğŸ”‘ OpenAI API Key: {'å·²è®¾ç½®' if openai_api_key else 'âŒ æœªè®¾ç½®'}")
    
    if not openai_api_key:
        print("âŒ è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("   export OPENAI_API_KEY='your-api-key-here'")
        return False
    
    # æµ‹è¯•APIè¿æ¥
    if not debug_arxiv_connection():
        return False
        
    if not debug_openai_connection(openai_api_key):
        return False
    
    # æµ‹è¯•è®ºæ–‡æŠ“å–å™¨
    print(f"\nğŸ“‹ å¼€å§‹æµ‹è¯•è®ºæ–‡æŠ“å–å™¨...")
    
    try:
        fetcher = ArxivPaperFetcher(openai_api_key)
        print("âœ… è®ºæ–‡æŠ“å–å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•è·å–æœ€è¿‘3å¤©çš„è®ºæ–‡ï¼ˆç¡®ä¿æœ‰ä¸€äº›ç»“æœï¼‰
        print(f"\nğŸ• æµ‹è¯•è·å–æœ€è¿‘3å¤©çš„è®ºæ–‡...")
        end_date = datetime.now(timezone.utc)
        start_date = end_date - timedelta(days=3)
        
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
        
        # é™åˆ¶åˆ°20ç¯‡è®ºæ–‡è¿›è¡Œæµ‹è¯•
        papers = fetcher.fetch_papers_by_date_range(start_date, end_date, max_papers=20)
        
        print(f"\nğŸ“Š æŠ“å–ç»“æœåˆ†æ:")
        print(f"   - æ€»å…±è·å–: {len(papers)} ç¯‡è®ºæ–‡")
        
        if papers:
            print(f"\nğŸ“„ è®ºæ–‡æ ·æœ¬ (å‰3ç¯‡):")
            for i, paper in enumerate(papers[:3], 1):
                print(f"\n   {i}. {paper['title']}")
                print(f"      å‘å¸ƒæ—¶é—´: {paper['published']}")
                print(f"      ç±»åˆ«: {', '.join(paper['categories'])}")
                print(f"      æ‘˜è¦é•¿åº¦: {len(paper['abstract'])} å­—ç¬¦")
            
            # æµ‹è¯•GPTè¿‡æ»¤ï¼ˆåªæµ‹è¯•å‰5ç¯‡ï¼‰
            print(f"\nğŸ¤– æµ‹è¯•GPT-4oè¿‡æ»¤ (å‰5ç¯‡è®ºæ–‡)...")
            sample_papers = papers[:5]
            filtered_papers = fetcher.filter_papers_with_gpt(sample_papers)
            
            print(f"\nğŸ¯ è¿‡æ»¤ç»“æœ:")
            print(f"   - è¾“å…¥è®ºæ–‡: {len(sample_papers)} ç¯‡")
            print(f"   - ç›¸å…³è®ºæ–‡: {len(filtered_papers)} ç¯‡")
            print(f"   - ç›¸å…³æ¯”ä¾‹: {len(filtered_papers)/len(sample_papers)*100:.1f}%")
            
            if filtered_papers:
                print(f"\nâœ… å‘ç°ç›¸å…³è®ºæ–‡:")
                for i, paper in enumerate(filtered_papers, 1):
                    print(f"   {i}. {paper['title']}")
            
            return True
        else:
            print("âš ï¸ æœªè·å–åˆ°ä»»ä½•è®ºæ–‡")
            print("å¯èƒ½çš„åŸå› :")
            print("   - æœ€è¿‘3å¤©å†…è¿™äº›ç±»åˆ«æ²¡æœ‰æ–°è®ºæ–‡")
            print("   - arXiv APIå“åº”å»¶è¿Ÿ")
            print("   - ç½‘ç»œè¿æ¥é—®é¢˜")
            return False
            
    except Exception as e:
        print(f"âŒ è®ºæ–‡æŠ“å–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
        return False


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ArXivè®ºæ–‡æŠ“å–ç³»ç»Ÿè°ƒè¯•...")
    
    success = debug_paper_fetch()
    
    print(f"\n" + "="*60)
    if success:
        print("âœ… è°ƒè¯•å®Œæˆï¼ç³»ç»Ÿå·¥ä½œæ­£å¸¸")
        print("\nğŸ¯ æ¥ä¸‹æ¥å¯ä»¥:")
        print("   - è¿è¡Œ python scripts/fetch_papers.py è¿›è¡Œå®é™…æŠ“å–")
        print("   - è¿è¡Œ python scripts/test_daily_fetch.py è¿›è¡Œå®Œæ•´æµ‹è¯•")
    else:
        print("âŒ è°ƒè¯•å‘ç°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        
    print("="*60) 